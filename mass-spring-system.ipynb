{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example was inspired by https://github.com/benmoseley/harmonic-oscillator-pinn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following to install the required packages\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['lines.markersize'] = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will learn the dynamics of a 1D dampened harmonic oscillator with unit mass, spring constant $k$ and dampening constant $\\mu$:\n",
    "$$\n",
    "\\dfrac{d^2 x}{d t^2} + \\mu \\dfrac{d x}{d t} + kx = 0~,\n",
    "$$\n",
    "from the initial conditions\n",
    "$$\n",
    "x(0) = 1~~,~~\\dfrac{d x}{d t} = 0~.\n",
    "$$\n",
    "\n",
    "### 1. Exact solution and data\n",
    "For the underdampened case,\n",
    "$$\n",
    "\\mu^2 < 4 k~,~~~~~\\text{with},\n",
    "$$\n",
    "the exact solution is given by \n",
    "$$\n",
    "x(t) = e^{-\\mu t/2}(\\cos(\\omega t))~,~~~~~\\mathrm{with}~~\\omega=\\sqrt{k - \\mu^2/4}~.\n",
    "$$\n",
    "In practice, we are given a data set that is the solution of a differntial equation. We make the *assumption* that the differential equation is of a known form (i.e., we know the physical equations).\n",
    "\n",
    " Let's turn the above exact solution into a function that we can use to generate a training data set $X_{\\mathrm{train}}$ consisting of points $(t_i, x_i)$, where $t_i$ are evenly spaced times on some interval and $x_i=x(t_i)$ is given by the above exact solution. We wil also create a test data set $X_{\\mathrm{test}}$ on a longer time interval. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MU = 4\n",
    "K = 400\n",
    "\n",
    "N_TRAIN = 20\n",
    "TMAX_TRAIN = 0.2\n",
    "\n",
    "N_TEST = 50\n",
    "TMAX_TEST = 1\n",
    "\n",
    "\n",
    "def exact_solution(t, k=K, mu=MU):\n",
    "    \"\"\"Get exact solution to the 1D underdamped harmonic oscillator.\"\"\"\n",
    "    d = mu / 2\n",
    "    w0 = k**0.5\n",
    "    assert d < w0, \"System must be underdamped.\"\n",
    "    w = np.sqrt(w0**2 - d**2)\n",
    "    x = torch.exp(-d * t) * torch.cos(w * t)\n",
    "    return x\n",
    "\n",
    "\n",
    "t_train = torch.linspace(0, TMAX_TRAIN, N_TRAIN + 1).reshape(-1, 1)\n",
    "t_test = torch.linspace(0, TMAX_TEST, N_TEST + 1).reshape(-1, 1)\n",
    "\n",
    "x_train = exact_solution(t_train)\n",
    "x_test = exact_solution(t_test)\n",
    "\n",
    "plt.plot(t_test, x_test, \"k-\", label=\"Test data (exact sol.)\")\n",
    "plt.plot(t_train, x_train, \"rx\", label=\"Train data\")\n",
    "plt.title(\"Data\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Learning the dynamics with a ***basic neural network*** \n",
    "Now we will set up a neural network $x_\\theta(t)$ to learn the dynamics $x(t)$ from the training data. We hope that it will generalise well to the test data, which is the exact solution over a longer time span. \n",
    "\n",
    "We do this by training the neural network on a loss function that minimises the mean squared error (MSE) between the predicted solution $x_{\\theta}(t_i)$ and the observed (exact solution) values $(t_i, x_i)\\in X_{\\mathrm{train}}$. \n",
    "\n",
    "$$L_{\\mathrm{data}} = \\sum_{(t_i, x_i)\\in X_{\\mathrm{train}}}\\|x_{\\theta}(t_i) - x_i\\|^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \"\"\"Defines a pytorch neural network with one hidden layer.\"\"\"\n",
    "\n",
    "    def __init__(self, input_size=1, hidden_size=32, output_size=1):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "def train_nn(model, t_train, x_train):\n",
    "    mse = nn.MSELoss()\n",
    "    torch.manual_seed(123)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    for i in range(10000):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute data loss\n",
    "        x_pred = model(t_train)\n",
    "        loss = mse(x_pred, x_train)\n",
    "\n",
    "        # backward pass and update parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"loss = {loss.item()}\") if i % 500 == 0 else None\n",
    "\n",
    "\n",
    "model_nn = NeuralNet()\n",
    "train_nn(model_nn, t_train=t_train, x_train=x_train)\n",
    "\n",
    "plt.plot(t_test, model_nn(t_test).detach().numpy(), 'b.', label='Neural Net')\n",
    "plt.plot(t_test, x_test, 'k-', label='Test data (exact sol.)')\n",
    "plt.plot(t_train, x_train, 'rx', label='Train data')\n",
    "plt.title(\"Purely data driven approach\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Learning the dynamics with a ***physics informed neural network***\n",
    "Now we will train the physics informed neural network (PINN). This is done in exactly the same way as before, but we augment the loss function with the \"physics loss\".\n",
    "\n",
    "$$L_{\\mathrm{PINN}}=L_{\\mathrm{data}} + L_{\\mathrm{phys.}}$$\n",
    "where\n",
    "$$L_{\\mathrm{phys.}} = \\sum_{t_i\\in X_{\\mathrm{phys.}}}\\|\\ddot{x}_{\\theta}(t_i)+ \\mu\\,\\dot{x}_{\\theta}(t_i) + k\\,x_{\\theta}(t_i)\\|^2,$$\n",
    "where $X_{\\mathrm{phys.}}$ are a set of times, chosen by us, that we choose to evaluate the *physics loss* on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose points to evaluate the physics loss with \n",
    "t_phys = np.random.uniform(0, 0.7, 50)\n",
    "\n",
    "model_pinn = NeuralNet(1,32,1)\n",
    "    \n",
    "def train_pinn(model, t_train, x_train, t_phys):\n",
    "    mse = nn.MSELoss()\n",
    "    t_phys = torch.tensor(t_phys, requires_grad=True, dtype=torch.float32).reshape(-1,1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "    for i in range(10000):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute data loss\n",
    "        x_pred = model(t_train)\n",
    "        loss = mse(x_pred, x_train) \n",
    "        \n",
    "        # compute physics loss\n",
    "        x_phys = model(t_phys)\n",
    "        xdot  = torch.autograd.grad(x_phys, t_phys, torch.ones_like(x_phys), create_graph=True)[0]# computes dx/dt\n",
    "        xddot = torch.autograd.grad(xdot,  t_phys, torch.ones_like(xdot),  create_graph=True)[0]# computes d^2x/dt^2\n",
    "        ode_residual = xddot + MU*xdot + K*x_phys \n",
    "        loss += (1e-4)*torch.mean(ode_residual**2)\n",
    "\n",
    "        # backward pass and update params\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"loss = {loss.item()}\") if i % 500 == 0 else None\n",
    "\n",
    "train_pinn(model_pinn, t_train, x_train, t_phys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_test, model_pinn(t_test).detach().numpy(), 'g.', label='PINN')\n",
    "plt.plot(t_test, model_nn(t_test).detach().numpy(), 'b.', label='Neural Net')\n",
    "plt.plot(t_test, x_test, 'k-', label='Test data (exact sol.)')\n",
    "plt.plot(t_train, x_train, 'rx', label='Train data')\n",
    "plt.plot(t_phys, 0*t_phys, 'cx', label='Phys. loss points')\n",
    "plt.title(\"PINN\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
